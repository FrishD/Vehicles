# מדריך למנהל - מערכת SkyGuard לאכיפת תנועה אווירית

ברוכים הבאים למערכת **SkyGuard**. מסמך זה מסביר בשפה פשוטה כיצד המערכת פועלת "מתחת למכסה המנוע", באילו טכנולוגיות היא משתמשת, וכיצד היא מקבלת החלטות לגבי עבירות תנועה בזמן אמת.

---

## 📸 1. המבט מלמעלה (Video Input)
המערכת מתחברת למצלמת הרחפן ומקבלת וידאו חי.
מכיוון שהרחפן זז, התמונה יכולה לרעוד או להשתנות. לשם כך פיתחנו שני מנגנונים חכמים:
* **ייצוב תמונה (Image Stabilization)**: המערכת משתמשת באלגוריתמים כדי "להחליק" רעידות ולשמור על תמונה ברורה.
* **שיפור ראות (Enhancement)**: במצבי גשם, ערפל או סנוור שמש, המערכת מפעילה פילטרים מיוחדים (CLAHE) שמחדדים את התמונה ומדגישים את האובייקטים בכביש לפני שהם מגיעים לניתוח ה-AI.

## 🧠 2. המוח שרואה הכל (Detection Core)
המערכת משתמשת במודל בינה מלאכותית מתקדם (**YOLOv8**), שאומן לזהות שלושה סוגי אובייקטים מרכזיים:
1. **רכבים** (מכוניות, משאיות, אוטובוסים, אופנועים)
2. **הולכי רגל**
3. **רמזורים**

### זיהוי ועקיבה (Tracking)
המערכת לא רק "רואה" מכונית בפריים בודד, אלא נותנת לה **מספר זהות (ID)** ייחודי ועוקבת אחריה לאורך זמן.
זה מאפשר למערכת להבין **התנהגות** ולא רק תמונת מצב רגעית. לדוגמה: "רכב מספר 42 מתקרב למעבר החצייה במהירות".

---

## 🚨 3. זיהוי העבירות (Logic Engine)

המערכת יודעת לזהות שתי עבירות מרכזיות באופן אוטומטי לחלוטין:

#### 3. לוגיקה היוריסטית ושדרוגים (Advanced Logic)
לא הכל זה AI. חלק מההחלטות הן אלגוריתמיקה קלאסית משודרגת:
* **זיהוי צבע רמזור HSV**: המרה למרחב צבע HSV (טונליות-רוויה-בהירות) מאפשרת עמידות לשינויי תאורה. אנו מפרידים את ערוץ ה-Value ומזהים צבע גם בתנאי סנוור.
* **מכונת מצבים (State Machine) עם Timeout**: המערכת שומרת על רצף לוגי (ירוק -> צהוב -> אדום). הוספנו מנגנון **Timeout** של 2 שניות: אם הרמזור לא זוהה במשך זמן זה (למשל יצא מהפריים), המצב מתאפס ל-unknown כדי למנוע דוחות שגויים על בסיס מידע ישן.

#### 4. פיצוי תנועה (GMC - Global Motion Compensation)
בעזרת **Optical Flow**, המערכת מחשבת את תזוזת המצלמה עצמה.
היתרון: וקטור התנועה של הרכב כעת מייצג את המהירות האמיתית שלו ביחס לכביש, ולא ביחס לרחפן. זה מונע זיהויים שגוים כשהרחפן פונה בחדות.

### א. חצייה באור אדום (Red Light Violation)
1. **זיהוי הרמזור**: המערכת סורקת את השטח ומאתרת את קופסת הרמזור.
2. **ניתוח צבע**: אלגוריתם מיוחד דוגם את הפיקסלים בתוך הרמזור ומחליט האם האור הוא 🔴 **אדום** או 🟢 **ירוק**.
3. **הפללה**: אם רכב (שהמערכת עוקבת אחריו) חוצה את קו העצירה הדמיוני ונכנס לקרבה מסוכנת לרמזור **כשהאור אדום**, המערכת מייצרת התראה.

### ב. אי-מתן זכות קדימה (Failure to Yield)
1. **חישוב מרחקים**: המערכת מחשבת כל הזמן את המרחק הפיזי בין כל רכב לבין כל הולך רגל בסביבה.
2. **אזור סכנה**: אם המרחק מצטמצם מתחת לסף בטיחות מסוים (למשל, קרבה של מטרים בודדים להולך רגל), המערכת מזהה זאת כסכנה.
3. **התראה**: נוצרת התראה מיידית על "אי מתן זכות קדימה" עם תמונה של הרכב המפר.

---

## 💻 4. הדשבורד (Dashboard)
כל המידע מוקרן למפעיל בזמן אמת על גבי מסך מחשב מעוצב:
* **וידאו חי**: רואים את מה שהרחפן רואה, עם קופסאות צבעוניות שמסמנות את הזיהויים (אדום = עבירה, כחול = תקין).
* **פאנל התראות**: בצד המסך מופיעה רשימה רצה של העבירות האחרונות.
* **סטטוס מערכת**: חיווי שהמערכת מחוברת ותקינה.

---

## � 5. דרישות מערכת וטכנולוגיה (Technical Specs)

### דרישות חומרה (Hardware)
המערכת מבצעת עיבוד תמונה כבד (Computer Vision) בזמן אמת, ולכן דורשת משאבים:
* **מעבד (CPU)**: מינימום Intel Core i7 או AMD Ryzen 7 (דורות חדשים).
* **כרטיס מסך (GPU)**: **קריטי לביצועים**. מומלץ NVIDIA RTX 3060 ומעלה עם תמיכה ב-CUDA. המערכת יכולה לרוץ על CPU, אך קצב הפריימים (FPS) יהיה איטי משמעותית.
* **זיכרון (RAM)**: מינימום 16GB.

### צלילה לעומק: ארכיטקטורה ואלגוריתמיקה (Technical Deep Dive)

פרק זה מיועד לצוות הפיתוח והמומחים הטכניים. הוא מפרט את ה"ברזלים" של האלגוריתמים.

#### 1. מודל הזיהוי: YOLOv8 (Architecture Breakdown)
המערכת משתמשת במודל **YOLOv8** (גרסת Nano/Small), שנחשב ל-SOTA (State of the Art) בזיהוי זמן-אמת.

**ארכיטקטורה פנימית:**
*   **Backbone (השדרה)**: מבוסס על **CSPDarknet53** משופר עם בלוקים מסוג C2f. בלוקים אלו משלבים בתוכם Cross Stage Partial networks, המאפשרים זרימת גרדיאנטים עשירה יותר תוך שמירה על משקל נמוך.
*   **Neck (הצוואר)**: משתמש ב-**PANet** (Path Aggregation Network). תפקידו לערבב פיצ'רים מרזולוציות שונות – כך המודל מצליח לזהות גם רכב גדול שקרוב למצלמה וגם רכב קטן שנמצא רחוק, על ידי "הזרקת" מידע סמנטי משכבות עמוקות לשכבות רדודות ולהפך.
*   **Head (הראש)**: חידוש משמעותי ב-YOLOv8 הוא ה-**Decoupled Head**. במקום ראש אחד שמחליט גם "איפה" וגם "מה", המודל מפריד לשני ענפים מקבילים:
    1.  **Objectness & Classification**: מהו האובייקט?
    2.  **Regression (Box Coordinates)**: איפה בדיוק הקופסה?

**פונקציות הפסד (Loss Functions):**
המודל אומן למזער שלוש שגיאות במקביל:
*   **VFL (Varifocal Loss)**: עבור הסיווג. נותן משקל גבוה יותר לדוגמאות קשות לזיהוי.
*   **CIoU (Complete IoU Loss)**: עבור התיבה. לוקח בחשבון לא רק חפיפה, אלא גם מרחק בין מרכזים ויחסי גובה-רוחב (Aspect Ratio).
*   **DFL (Distribution Focal Loss)**: עוזר לדייק את גבולות התיבה כשהם לא ברורים (מטושטשים).

**ביצועים (Benchmarks):**
על בסיס COCO Dataset, מודל YOLOv8n משיג כ-**37.3% mAP@50-95**, ומודל YOLOv8s משיג כ-**44.9%**.
בזמן אמת על GPU מודרני (T4/RTX3060), המודל מסוגל לרוץ ב-**100+ FPS** (תלוי ברזולוציית הקלט).

#### 2. מנגנון העקיבה: ByteTrack (Multi-Object Tracking)
האתגר הגדול ברחפנים הוא Occlusion (הסתרה) וטשטוש תנועה. אנו משתמשים ב-**ByteTrack**, שנחשב לאלגוריתם מוביל כי הוא מנצל גם זיהויים "חלשים".

**תהליך העקיבה (The Pipeline):**
1.  **Kalman Filter Prediction**: לכל רכב יש "תיק אישי" (Tracklet). הפילטר חוזה איפה הרכב *אמור* להיות בפריים הבא על בסיס וקטור מהירות (Constant Velocity Model).
2.  **שלב ראשון (High Confidence Matching)**: המערכת לוקחת את כל הזיהויים החזקים (מעל 0.6) ומשדכת אותם למסלולים קיימים באמצעות **IoU (Intersection over Union)** ו-Hungarian Algorithm.
3.  **שלב שני (Low Confidence Recovery)**: זהו הקסם של ByteTrack. במקום לזרוק זיהויים חלשים (למשל 0.2, כשהרכב מוסתר חלקית), המערכת מנסה לשדך אותם למסלולים שנותרו "יתומים" מהשלב הראשון. זה מציל רכבים שנעלמו לרגע בגלל עץ או סינוור.

#### 3. ייצוב לוגי וגיאומטרי
מכיוון שהרחפן בתנועה 6DoF (שש דרגות חופש), אי אפשר להסתמך על פיקסלים קבועים.
*   **Dynamic ROI**: אזורי העניין (רמזור) מזוהים דינמית בכל פריים מחדש.
*   **Logic Smoothing**: כדי למנוע "הבהוב" (Flickering) של התראות, אנו משתמשים ב-Buffer. רכב צריך להיות מזוהה כ"מפר" למשך X פריימים רצופים (Temporal Consistency) לפני שמופקת התראה, כדי למנוע False Positives מרעש רגעי.

---

## 📡 6. יכולות מתקדמות ועתידיות
* **Logging ותחקור**: כל עבירה נשמרת בקובץ לוג (`violations.log`) עם חותמת זמן, מזהה רכב, וסוג העבירה. ניתן לשמור גם תמונת סטילס של רגע העבירה להוכחה משפטית.
* **התראות חיצוניות**: המערכת בנויה בצורה מודולרית (FastAPI), כך שניתן בקלות לחבר Webhook שישלח SMS למפעיל או מייל למשטרה ברגע שמזוהה עבירה חמורה.

---

## 🛡 7. טיפול במקרי קצה ובטיחות (Edge Cases & Safety)

### מה קורה כשהמערכת "לא רואה"? (Fail-Safe)
*   **רמזור נעלם**: אם המערכת מזהה רכב בצומת אך *לא* מצליחה לזהות רמזור (למשל, הסתרה מלאה או סינוור קיצוני), היא **לעולם לא תפיק דוח עבירה**. ברירת המחדל היא "חפות מפשע" כדי למנוע דוחות שווא.
*   **הודעה למפעיל**: במקרים של ירידה דרסטית באחוזי הזיהוי (Low Confidence) לאורך זמן, המערכת תסמן למפעיל בצבע צהוב שיש "הפרעה בראות".

### ניהול שגיאות (False Positives/Negatives)
*   **סף ביטחון (Confidence Threshold)**: המערכת מתעלמת מכל זיהוי שהסבירות שלו נמוכה מ-50% (0.5).
*   **עקביות בזמן (Temporal Consistency)**: כדי למנוע מרכב "לקפוץ" לרגע לצבע אדום בגלל רעש בתמונה, המערכת דורשת רצף של 3-5 פריימים שבהם העבירה מתקיימת לפני שהיא מכריזה על "אירוע".
*   **סינון גודל**: זיהויים שטויות (קטנים מדי או גדולים מדי באופן לא פרופורציונלי) מסוננים אוטומטית.

### זמנים ו-Latency
המערכת היא **Real-Time**.
*   **זמן תגובה**: העיכוב (Latency) בין המציאות להופעה על המסך הוא מתחת ל-100 מילישניות (בתקשורת מקומית).
*   **חישוב**: העיבוד נעשה במקביל (Async) כך שפענוח הוידאו לא מעכב את ה-AI.

### תנאי סביבה קשים והסתרה (Occlusion)
*   **לילה וחושך**: המודל הנוכחי אומן בעיקר ליום. בלילה מוחלט הביצועים ירדו, אך במקומות עם תאורת רחוב טובה הוא ימשיך לתפקד.
*   **סנוור/צל**: אלגוריתם ה-CLAHE (שיפור ניגודיות מקומי) שהטמענו נועד בדיוק לזה – הוא "פותח" אזורים מוצלים ומכהה אזורים מסנוורים לפני שהתמונה מגיעה ל-AI.
*   **הסתרה (Occlusion)**: כאן נכנס **ByteTrack**. אם עץ מסתיר את הרכב לחצי שנייה, המערכת "זוכרת" איפה הוא היה ומשערת את מיקומו, כך שכשהוא יוצא מההסתרה, הוא נשאר עם אותו מספר זיהוי ולא נספר כרכב חדש.

### דיוק גיאומטרי וקו עצירה
כרגע, המערכת משתמשת ב**לוגיקה יחסית (Spatial Proximity)**.
*   היא לא מחשבת קואורדינטות GPS (כי לרחפן אין תמיד RTK מדויק).
*   במקום זאת, היא מודדת מרחק פיקסלים יחסי לגודל הרכב. אם רכב נמצא ב"אזור סכנה" (רדיוס סביב רמזור אדום), זה נחשב כחצייה.
*   **בעתיד**: ניתן להוסיף מטריצת המרה (Homography Matrix) כדי לתרגם פיקסלים למטרים מדויקים, אך זה דורש כיול מצלמה מול הכביש.

### מיקרו-מוביליטי (קורקינטים ואופניים)
המודל (COCO) תומך ומזהה גם:
*   Bicycle (אופניים)
*   Motorcycle (אופנוע/קטנוע)
*   היגיון העבירות ("אור אדום") תקף גם לגביהם באותה מידה.

### פיצול נתיב (Lane Splitting) ואכיפת דו-גלגלי
האלגוריתם מתוכנן לזהות גם אופנועים המבצעים עקיפות מסוכנות או נסיעה על השוליים, באמצעות ניתוח של חריגה מקווי סימון הנתיב (Lane Extraction).

### הבהרה לגבי זיהוי לוחית רישוי (LPR/ANPR)
חשוב להדגיש: **בגרסה הנוכחית, המערכת מציגה "מספר מעקב" (Tracker ID) ולא את לוחית הרישוי האמיתית**.
*   **הסיבה הטכנית**: מודל YOLOv8 הסטנדרטי מזהה "רכב" אך לא "לוחית רישוי".
*   **הפתרון המתוכנן (Roadmap)**:
    1.  אימון מודל קטן ייעודי (YOLO-Plate) שירוץ רק על ה-Crop של הרכבים החשודים.
    2.  הפעלת מנוע OCR (כגון EasyOCR או LPRNet) על אזור הלוחית.
    3.  החלפת ה-Tracker ID במספר הרישוי בדוח הסופי.
    *התשתית בקוד (Reporting Module) מוכנה לקלוט את המחרוזת הזו ברגע שהמודל יוטמע.*

### כיול מרחקים דינמי (Dynamic Scaling)
אחת הבעיות הקשות ברחפנים היא שינוי הגובה (Altitude).
*   **הבעיה**: "מרחק סכנה" של 20 פיקסלים נראה אחרת לחלוטין מגובה 20 מטר לעומת גובה 50 מטר.
*   **הפתרון החכם**: המערכת משתמשת ב**רוחב הרכב כסרגל מדידה**.
    *   אנו יודעים שרוחב ממוצע של רכב פרטי הוא כ-1.8 מטר.
    *   בכל פריים, המערכת מודדת כמה פיקסלים תופס רוחב הרכב, ומחשבת את היחס "פיקסל למטר" (PPM - Pixels Per Meter).
    *   כך שגם אם הרחפן ממריא או נוחת, חישובי המרחק והמהירות נשארים מדויקים הנדסית וללא צורך ב-GPS.

### למידה מתמדת (Continual Learning) - עתידי
המערכת מוכנה ל-**Active Learning**:
ניתן להגדיר לה לשמור בצד תמונות שבהן היא "התלבטה" (Confidence 0.4-0.6). מפעיל אנושי יכול לתייג אותן ידנית בסוף היום, ולאמן את המודל מחדש (Fine-Tuning) כדי שישתפר ספציפית לזווית הצילום ולתנאי התאורה של אותו צומת.

---

## 🚀 איך מריצים?
פשוט וקל:
הקובץ `run_system.py` שנמצא בתיקייה הראשית מפעיל אוטומטית את כל רכיבי המערכת בלחיצת כפתור אחת.
